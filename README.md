# ğŸ§  GazeCraze - Real-Time Concentration Detection Using Face Landmarks

**GazeCraze** is a modular Python application that uses computer vision and facial landmark detection to analyze user concentration in real-time. It leverages MediaPipe Face Mesh, OpenCV, and head/eye tracking techniques to infer gaze alignment and focus level from webcam video streams.


## ğŸš€ Features

- ğŸ” **Face Mesh Tracking** via MediaPipe
- ğŸ‘ï¸ **Gaze and Iris Alignment** for focus estimation
- ğŸ§  **Head Pose Analysis** to determine attention direction
- ğŸ§ª **Modular Testable Architecture**
- ğŸ“ˆ **Real-time Visualization & Display**


## ğŸ“‚ Project Structure

```
GazeCraze/
â”œâ”€â”€ notebooks/
â”œâ”€â”€ src/ # Source code
â”‚   â”œâ”€â”€ main.py # Entry point
â”‚   â”œâ”€â”€ concentration_detector.py
â”‚   â””â”€â”€ modules/ # Modular components
â”‚       â”œâ”€â”€ face_mesh_processor.py
â”‚       â”œâ”€â”€ eye_analyzer.py
â”‚       â”œâ”€â”€ head_pose_analyzer.py
â”‚       â”œâ”€â”€ concentration_analyzer.py
â”‚       â”œâ”€â”€ result_smoother.py
â”‚       â”œâ”€â”€ performance_tracker.py
â”‚       â”œâ”€â”€ camera_manager.py
â”‚       â””â”€â”€ display_manager.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ run_tests.py
â”‚   â””â”€â”€ test_*.py # Tests for each module
â”œâ”€â”€ utils/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```


## ğŸ› ï¸ Installation

### 1. Clone the repository

```bash
git clone https://github.com/daveshenal/GazeCraze.git
cd GazeCraze
```

### 2. Create a virtual environment

```bash
python -m venv venv
source venv/bin/activate      # Linux/macOS
venv\Scripts\activate         # Windows
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

## ğŸ§ª Running the Application

```bash
python -m src.main
```

Make sure your webcam is connected. A window will open showing real-time concentration detection based on face and gaze tracking.



## ğŸ“Š Notebooks

Explore the logic and debugging tools via Jupyter notebooks in the `notebooks/` directory:

- [`face_mesh.ipynb`](notebooks/face_mesh.ipynb) â€“ Debug and understand MediaPipe's face mesh outputs.
- [`eye_indexes.ipynb`](notebooks/eye_indexes.ipynb) â€“ Visualize eye region indices and landmark positions.

These notebooks help visualize facial landmarks and debug model behavior effectively.


## ğŸ‘¤ Author

**Dave Perera**  
_Machine Learning Engineer_

- [ğŸ”— LinkedIn](https://www.linkedin.com/in/davesperera)
- [ğŸ”— Email](daveshenal281@gmail.com)


## ğŸ™ Acknowledgements

This project is made possible by the following technologies:

- [MediaPipe](https://mediapipe.dev/)
- [OpenCV](https://opencv.org/)
